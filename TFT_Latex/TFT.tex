\documentclass[12pt,a4paper]{scrreprt}

% Gráficos y geometría
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage[left=2.75cm,right=2.6cm,top=3.5cm,bottom=3.5cm]{geometry}


% Índices y listas
\usepackage{titletoc}
\usepackage[shortlabels]{enumitem}
\newlist{bulletlist}{itemize}{1} % Definición de una lista personalizada llamada "bulletlist"
\setlist[bulletlist]{label=\LARGE\textbullet, left=1.3em}


% Colores
\usepackage[table]{xcolor}
\definecolor{naranja}{HTML}{E65113}
\definecolor{slcolor}{HTML}{E65113}
\newcommand{\headlinecolor}{\color{slcolor}}
\definecolor{gray75}{gray}{0.75}


\newcommand{\hsp}{\hspace{-10pt}}

% URLs e hipervínculos
\usepackage{url}
\usepackage{hyperref}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%------------------COMANDOS PARA EL TIPO DE LETRA---------------------------%
\usepackage{fontspec}
\usepackage[T1]{fontenc}
\usepackage{helvet}
\renewcommand{\familydefault}{\sfdefault}

% Estilo de capítulos y secciones con KOMA-Script
\usepackage{xcolor}
\setkomafont{chapter}{\Huge\bfseries\headlinecolor}
\setkomafont{section}{\Large\bfseries}
\setkomafont{subsection}{\normalsize\bfseries}
\setkomafont{sectioning}{\bfseries}




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%-------------------COMANDOS PARA TABLAS  E IMAGENES ---------------------%
\usepackage{tikz}
\usepackage{tabularx}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%-----------------COMANDOS PARA CABECERAS Y PIE DE PAGINA -----------------%
\usepackage{lastpage}
\usepackage{fancyhdr}

\fancypagestyle{plain}{%
  \renewcommand{\headrulewidth}{0pt}
\fancyhead{}
\fancyfoot{}
\fancyfoot[R]{{\scriptsize\thepage\ de \pageref{LastPage} | Título del TFT}}
\fancyhead[L]{\tikz[remember picture,overlay]\node[opacity=0.4] at (-3mm, 10mm){\includegraphics[scale=0.18]{./Images/image3.png}};}
\fancyheadoffset{0pt}
}

\pagestyle{plain}


% Palabras clave
\providecommand{\keywords}[1]
{
  \small	
  \textbf{\textit{Palabras clave:\hspace{0.3cm}}} #1
}

% Bibliografía APA
%\usepackage[utf8]{inputenc} % no hace falta con xelatex
\usepackage[spanish]{babel} 
\usepackage{csquotes}
\usepackage[backend=biber, style=apa]{biblatex}
\addbibresource{Bibliografia_TFT.bib}

% Interlineado y espaciado entre párrafos
\usepackage{setspace}
\setstretch{1.2} % interlineado 1.3
\setlength{\parskip}{0.8em} % espacio entre párrafos



%%%%%%-------------------+++++++++--INICIO DEL DOCUMENTO--+++++++++---------------------------%%%%%

\begin{document}



%------------------XXXX++++++ INICIO DE PORTADA  ++++++XXXXX-----------------%
\begin{titlepage}

\newgeometry{left=2.5cm, bottom=3cm, top=2cm, right=2.5cm}

\tikz[remember picture,overlay] \node[opacity=1,inner sep=0pt] at (73.6mm, -124.25mm){\includegraphics{./Images/Picture_TitlePage.jpg}};

{\fontfamily{phv}\selectfont
%\fontsize{25}{10.4}\fontseries{b}\selectfont
\fontsize{25}{25}\fontseries{b}\selectfont
%\vspace{14cm}
\vspace{13cm}
\textbf{Desarrollo de un sistema de\\
diagnóstico de enfermedades\\
en hojas de tomate mediante\\ 
modelos de aprendizaje profundo}

\vfill

\fontsize{12}{12}\selectfont
\fontseries{m}\selectfont
\vspace{5cm}
\centering
\begin{tabularx}{1\textwidth} { 
  || >{\raggedright}X 
  || >{\centering}X 
  || >{\raggedleft\arraybackslash}X || }
 Titulación:\\Máster en Big Data y Ciencia de Datos\\ 
 & Alumno/a: Marín Lucas, Rubén\\DNI: 07272889-J 
 & Convocatoria: \\
 Curso Académico\\ 2024-2025 
  & Director/a del TFT: Ricardo Lebrón Aguilar   
  & SEGUNDA  \\
\end{tabularx}
 }
\end{titlepage}
%--------------------XXXX++++++ FIN DE PORTADA  ++++++XXXXX-----------------%
\tableofcontents	
\addcontentsline{toc}{chapter}{\listfigurename}
\addcontentsline{toc}{chapter}{\listtablename}
\listoffigures
\listoftables

\begin{abstract}
Lorem ipsum (RESUMEN)
\vspace{0.5cm}

\keywords{primero, segundo, tercero}
\end{abstract}
\newpage
\section*{Agradecimientos}\label{sec:agradecimientos}
Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.

	

\chapter{Introducción}\label{cap:cap1}

\section{Motivación}\label{sec:sec1.1}

Tomate o tomatera (\textit{Solanum lycopersicum}) es una planta herbácea de la familia Solanaceae cultivada en todo el mundo para el cultivo de su fruto, el tomate o jitomate, uno de los ingredientes más universales de ensaladas y salsas en el mundo entero. \parencite{wikipedia1} 

Según los últimos estudios filogenéticos, la planta silvestre de la cual surge el tomate doméstico actual tiene origen en la zona andina del norte de Perú y sur de Ecuador. Su domesticación y diversificación posterior se originó en México.

Los pueblos aztecas y mayas lo usaban en su cocina y fue exportado al resto del mundo a partir de la llegada de los españoles que lo distribuyeron a lo largo de sus colonias en el Caribe y la península ibérica a partir de lo cual pudo llegar al resto de eruopa. También lo llevaron a Filipinas y de allí pudo entrar al continente asiático. \parencite{agrotendencia1} 

\begin{figure}[ht]
\begin{center}
\includegraphics[scale=0.2]{./Images/Distribucion_tomate.jpg}
\caption{\headlinecolor{\underline{Origen del tomate}}}

\label{fig:fig1}

\end{center}
\end{figure}

La producción mundial de tomate ascendió a más de 186 millones de toneladas en 2022 según los datos de la Organización de las Naciones Unidas para la Alimentación y la Agricultura (FAO). Según esta misma organización esta es la evolución de los 20 países que más han producido hasta 2022: \parencite{wikipedia2}

\begin{table}[ht] 
\centering
\caption{\headlinecolor{\underline{Top 20 países productores de tomates 2022}}}
\label{tab:producción_mundial_tomate}
\begin{tabular}{|c|c|c|c|c|} \hline
\rowcolor{naranja}
\multicolumn{5}{|c|}{\textbf{Titulo}} \\ \hline
\rowcolor{naranja!30}
País & 2000 & 2010 & 2020 & 2022 \\ \hline
China & 22 200 & 46 760 & 64 680 & 68 242 \\ \hline
... & ... & ... & ... & ... \\ \hline
\end{tabular}
\end{table}

Como ya se ha mencionado, el cultivo de tomate es uno de los cultivos hortícolas más importantes a nivel mundial. Sin embargo, su producción se ve amenazada por una amplia variedad de enfermedades causadas por hongos, bacterias, virus y nematodos. Estas enfermedades pueden provocar una bajada de rendimiento que van desde reducciones parciales hasta la pérdida completa de la cosecha.

Entre las enfermedades más comunes se encuentran:

\begin{itemize}[label=\textbullet]
\item Tizón tardío (\textit{Phytophthora infestans}): Puede destruir por completo una plantación si no se controla a tiempo, especialmente en condiciones húmedas y templadas.

\begin{figure}[ht]
\begin{center}
\includegraphics[scale=0.4]{./Images/Tizon_tardio_tomate.jpg}
\caption{\headlinecolor{\underline{Tizón tardío en una planta de tomate}}}
\label{fig:fig2}
\end{center}
\end{figure}

\item Tizón temprano (\textit{Alternaria solani}): Produce defoliación progresiva, debilitando la planta y reduciendo el número y calidad de los frutos.

\begin{figure}[ht]
\begin{center}
\includegraphics[scale=0.2]{./Images/Tizon_temprano_tomate.jpg}
\caption{\headlinecolor{\underline{Tizón temprano en una planta de tomate}}}
\label{fig:fig3}
\end{center}
\end{figure}

\item Fusariosis vascular (\textit{Fusarium oxysporum}): Ataca el sistema vascular, provocando marchitez y muerte de plantas.
\item Virus como TYLCV y TSWV: Pueden causar deformaciones severas y reducciones completas en la producción, especialmente cuando se transmiten por vectores como la mosca blanca.
\end{itemize}

La manifestación simultánea o sucesiva de estas enfermedades es una de las principales causas en la disminución en la productividad del cultivo a escala global. Además, muchas de estas enfermedades no solo viven en la planta sino que persisten en el suelo, semillas o herramientas que hayan inteactuado con la planta, lo que dificulta su erradicación y aumenta los costos del tratamiento. \parencite{agrotendencia2}

Dada la magnitud del impacto de estas enfermedades, la detección temprana y precisa de las mismas es crucial. Permite una correcta intervención que minimiza las pérdidas, permitiendo la reducción del uso innecesario de los agroquímicos y mejorando la sostenibilidad. En este contexto, las tecnologías basadas en visión por computadora, sensores remotos e inteligencia artificial ofrecen soluciones eficaces para mejorar el seguimiento y el control sanitario de este cultivo clave.


\section{Estructura del resto del documento}\label{sec:sec1.2}

La documentación de este proyecto se ha desarrollado dividiendo el contenidoen distintos caítulos con el objetivo de facilitar la comprensión por parte del lector. A continuación se enuncia la información presente en cada capítulo del resto del documento:

\begin{bulletlist}
\item Capítulo 2. Objetivos: se describe el objetivo principal del proyecto junto con los objetivos intermedios necesarios para conseguirlo.
\item Capítulo 3. Estado del Arte: 
\item Capítulo 4. Implementación y desarrollo: se explica el preprocesamientode los datos y las técnicas ML aplicadas a los mismos.
\item Capítulo 5. Evaluación y resultados: se presentan los resultados obtenidos al aplicar las técnicas ML.
\item Capítulo 6. Conclusiones
\end{bulletlist}



\chapter{Objetivos}\label{cap:cap2}

El objetivo general de este proyecto consiste en conseguir un clasificador que a partir de imágenes de hojas de plantas de tomate distinga entre estado saludable y 10 enfermedades distintas.

\section{Objetivos específicos}\label{sec:sec2.1}

\begin{enumerate}[label=\bfseries\headlinecolor\arabic*.]
\item Analizar dataset de hojas de tomate.
\item Implementar y entrenar modelos CNN para la clasificación.
\item Evaluar la precisión de los modelos y comparar resultados.

\end{enumerate}


\chapter{Estado del arte}\label{cap:cap3}

En los últimos años la aplicación de técnicas de inteligencia artificial en la agricultura ha cobrado un papel relevante, especialmente en tareas de diagnóstico temprano de enfermedades en cultivos.  El uso de aprendizaje profundo permite automatizar la detección de patrones en imágenes, lo cual puede ayudar a los agricultores a tomar decisiones más rápidas y eficientes.

Inicialmente, los métodos empleados para esta tarea incluían algoritmos de aprendizaje supervisado como máquinas de vectores de soporte (SVM), k\-vecinos más cercanos (KNN) y redes bayesianas. Sin embargo, estos enfoques dependían en gran medida de una segmentación previa precisa y de la extracción manual de características, lo que limitaba su capacidad de generalización y precisión en entornos reales.

Con la llegada de las redes neuronales convolucionales (CNN), se ha producido un cambio significativo en la forma de abordar este problema. Las CNN son capaces de aprender representaciones directamente a partir de los datos de imagen, eliminando la necesidad de ingeniería manual de características. Diversos estudios han demostrado su eficacia para la clasificación de enfermedades en hojas de tomate.

Por ejemplo, una revisión publicada en la Revista de Investigación e Innovación de las Ciencias de la Universidad Tecnológica de Bolívar \parencite{estudio1}, las técnicas tradicionales de aprendizaje supervisado como SVM, KNN y lógica difusa muestran limitaciones significativas en tareas de detección de enfermedades en imágenes de frutas debido a su dependencia de extracción manual de características y segmentación previa. En contraste, las redes neuronales convolucionales han demostrado una precisión superior, mayor robustez frente a la variabilidad y mayor capacidad de generalización. Esta revisión respalda la elección de CNNs como enfoque principal en este trabajo.

Por otra parte, Valeria Maeda Gutiérrez (2019) \parencite{estudio2} realizó una comparativa entre varias arquitecturas CNN, incluyendo AlexNet, GoogleNet, InceptionV3, ResNet 18 y ResNet 50 aplicadas al conjunto de datos PlantVillage. Todas las arquitecturas consiguieron más del 98\% de precisión y sensibilidad, lo que confirma la ideonidad de las mismas para la tarea que se pretende hacer. Concretamente con GoogleNet consiguió una precisión del 99,3\% y una sensibilidad del 99,1\%

En otra línea, Eduardo A.Huerta-Mora, Víctor González-Huitrón, Héctor Rodríguez-Rangel y Leonel Ernesto Amabilis-Sosa (2024) \parencite{estudio3} emplearon la arquitectura VGG16 con técnicas de fine-tuning para el mismo conjunto de datos PlantVillage, obteniendo alrededor del 90\% de sensibilidad y precisión. Este hecho confirma que esta arquitectura también puede ser interesante para el estudia a realizar.



\chapter{Implementación y desarrollo}\label{cap:cap4}

En este capítulo se presenta tanto el \textit{hardware} como el \textit{software} usados en este proyecto. Además se explica la procedencia y estructura del conjunto de datos que serán usados para el estudio. Finalmente, se desarrolla el preprocesmiento que se realiza a este conjunto de datos junto con los modelos entrenados para conseguir un clasificador.

\section{Herramientas usadas}\label{sec:sec4.1}

Para llevar a cabo este proyecto, se ha usado Google Colab (abreviatura de Google Colaboratory) que se accedía desde el ordenador portátil del autor del documento. Este ordenador es un ASUS TUF Gaming FX505GT que cuenta con las siguientes características:

\begin{bulletlist}
\item 16 GB de RAM con formato DDR4.
\item Almacenamiento compuesto por un disco duro con tecnología SSD de 512GB.
\item Procesador Intel Core i7-9750H CPU a 2.60 GHz, con 6 procesadores principales y 6 procesadores lógicos.
\item Tarjeta gráfica NVIDIA GeForce GTX 1650 con 4GB de RAM.
\end{bulletlist}

Google Colab es un servicio gratuito de Google que permite escribir y ejecutar código en la nube sin necesidad de instalar nada en tu equipo. Los recursos que ofrece de forma gratuita varían con el tiempo, pero las características que suele ofrecer son las siguientes:

\begin{bulletlist}
\item GPU NVIDIA Tesla T4 con 16 GB de VRAM ó CPU Intel Xeon con alrededor de 13 GB de RAM.
\item Almacenamiento temporal se corresponde con unos 100 GB de espacio en disco.
\item La duración de la sesión puede ser de hasta 12 horas, aunque en la práctica podrían terminarse antes según uso y carga del sistema.
\end{bulletlist}

Por otra parte el lenguaje de programación usado ha sido Python, un lenguaje que es ampliamente utilizado por científicos de datos. En las últimas décadas Python se ha enriquecido con numerosas librerías relacionadas con técnicas de ML que facilitan el uso de las mismas. En concreto para este proyecto se ha utilizado la versión 3.12.11 de Python.

En cuanto a las librerías de Python usadas para la implementación, se presentan a continuación:

\begin{bulletlist}
\item NumPy: es una librería que ofrece la posibilidad de crear matrices y vectores multidimensionales y provee además un gran número de operaciones matemáticas de alto nivel.
\item Pandas: es una librería que ofrece la estructura de datos llamada DataFrame que facilita la manipulación y el análisis de datos. Es una extensión de la librería NumPy. Ha sido usada para tratar y transformar los datos.
\item Plantcv: es una librería de Python de código abierto diseñada específicamente para el análisis de imágenes de plantas. Se ha usado para lectura de las imágenes.
\item Tensorflow: es una librería de software de código abierto creada por Google para desarrollar y entrenar modelos de machine learning (ML) y deep learning (DL). Recibe este nombre porque trabaja con tensores, estructuras de datos multidimensionales, como matrices o vectores que fluyen a través de un grafo computacional de operaciones. Se ha usado para crear y entrenar los modelos descritos en este proyecto.
\item Seaborn: esta librería permite la visualización de los datos a través de distintos tipos de gráficas. Ha sido usada para realizar los distintos gráficos como las matrices de confusión para evaluar los modelos.
\item Sklearn: .
\end{bulletlist}


\section{Procedencia y descripción de los datos}\label{sec:sec4.2}

Los datos provienen de la plataforma online de ciencia de datos de Google, Kaggle, que funciona como una mezcla de red social, repositorio de datasets y espacio de competición. En concreto, el conjunto de datos usuado es el llamado "Tomato Leaves Dataset" (***Enlace). Según su descripción en la misma plataforma se trata de un conjunto de datos de más de 20.000 imágenes de hojas de tomate con 11 clases, 10 enfermedades y una clase sana. Estas imágenes se han recopilado tanto en entornos de laboratorio como en entornos naturales.

En concreto se pueden extraer dos directorios que servirán como conjunto de datos para el entrenamiento y conjunto de datos para validación, ambos cuentan con 11 directorios con imágenes dentro. Cada uno de estos subdirectorios representa una de las clases que serán brevemente expuestas a continuación:

\begin{table}[ht] 
\centering
\caption{\headlinecolor{\underline{Clases del conjunto de datos}}}
\label{tab:clases_datos}
\begin{tabular}{|c|c|} \hline
\rowcolor{naranja}
\multicolumn{2}{|c|}{\textbf{Conjunto de datos}} \\ \hline
\rowcolor{naranja!30}
Clase & Traducción Clase \\ \hline 
\texttt{Healthy} & Saludable \\ \hline 
\texttt{Bacterial\_spot} & Manchas bacterianas \\ \hline 
\texttt{Early\_blight} & Tizón precoz \\ \hline 
\texttt{Late\_blight} & Tizón tardío \\ \hline 
\texttt{Leaf\_Mold} & Hojas con moho \\ \hline 
\texttt{Powdery\_mildew} & Moho polvoriento \\ \hline 
\texttt{Septoria\_leaf\_spot} & Hojas manchadas de septoriosis \\ \hline 
\texttt{Spidermite\_Two-spotted\_spider\_mite} & Picadura de araña roja de dos manchas \\ \hline 
\texttt{Target\_Spot} & Punto blanco \\ \hline 
\texttt{Tomato\_mosaic\_virus} & Virus mosaico \\ \hline 
\texttt{Tomato\_Yellow\_Leaf\_Curl\_Virus} & Virus de la hoja amarilla \\ \hline
\end{tabular}
\end{table}


\section{Preprocesado de los datos}\label{sec:sec4.3}

Al realizar la carga de datos se tiene un directorio con dos subdirectorios, cada uno de ellos representará un conjunto de datos, uno de datos de entrenamiento (train) y otro de validación (valid). Cada uno de estos directorios contienen a su vez 11 directorios, representando cada una de las clases. 

Llegados a este punto, se llevan a cabo las primeras tareas de exploración de las imágenes.

En primer lugar, seleccionando el directorio que contiene los datos de entrenamiento se realiza una función para obtener el número de imágenes existentes por cada tipo de tamaño. Gracias a esta función se sabe que se cuentan con imágenes de variables tamaños, concretamente existen 760 tipos de tamaños distintos. En la siguiente tabla se exponen los 5 tipos de tamaño que más se repiten:

\begin{table}[ht] 
\centering
\caption{\headlinecolor{\underline{Los 5 tamaños de imágenes más comunes}}}
\label{tab:tamanos_imagenes}
\begin{tabular}{|c|c|} \hline
\rowcolor{naranja}
\multicolumn{2}{|c|}{\textbf{Top 5 tamaños de imágenes}} \\ \hline
\rowcolor{naranja!30}
Tamaño (píxeles) & N\textsuperscript{o} imágenes \\ \hline 
256x256 & 18942 \\ \hline 
227x227 & 4120 \\ \hline 
640x640 & 1207 \\ \hline 
533x800 & 151 \\ \hline 
800x600 & 10 \\ \hline
\end{tabular}
\end{table}

De cara a construir un modelo todas las imágenes tienen que tener el mismo tamaño y debida a esta primera toma de contacto se toma la decisión de transformar todas las imágenes a tamaño de 256x256 píxeles.

En segundo lugar, se realiza una muestra aleatoria de una imagen por clase, para visualizar el tipo de imágenes que se vana tratar.

\begin{figure}[ht]
\begin{center}
\includegraphics[scale=0.4]{./Images/Imagen_aleatoria_por_clase.png}
\caption{\headlinecolor{\underline{Imagen aleatoria por clase}}}
\label{fig:fig4}
\end{center}
\end{figure}

Se puede observar la gran variedad de imágenes que existen, con distintos brillos, distintos fondos o incluso giradas:

\begin{bulletlist}
\item En cuanto al brillo se puede observar que la imagen de \texttt{Target\_Spot} tiene mucho más brillo que la de \texttt{Tomato\_Yellow\_Leaf\_Curl\_Virus}.
\item Con respecto al fondo podemos vir distinciones entre la imagen \texttt{Bacterial\_spot} con un fondo grisáceo plano, la imagen \texttt{Late\_blight} con fondo completamente negro y la foto \texttt{Early\_blight} en la que se ve el resto de la planta de tomate, no solo se ve una hoja.
\item También se puede destacar la diferencia entre las posiciones de las hojas, algunas como \texttt{Bacterial\_spot} tienen el tallo abajo, otras como \texttt{Leaf\_Mold} tienen el tallo arriba y otras como \texttt{Septoria\_leaf\_spot} tienen el tallo horizontal. 
\item Además se tiene un ejemplo de imagen rotada, concretamente la \texttt{Septoria\-\_leaf\_spot}
\end{bulletlist}

Debido a esta gran variedad de imágenes y de enfermedades se llegó a la conclusión de que no tiene mucho sentido usar funciones especiales de la librería PlantCV, ya que esta está muy orientada al fenotipado clásico (área, forma, color, índices), y esas características a veces no capturan la complejidad de patrones de enfermedades, que suelen ser más sutiles y no lineales. La estrategia que se ha seguido es pasar a un pipeline de deep learning con imágenes preprocesadas de forma estándar. De esta manera el modelo aprenderá por si mismo las características discriminantes en lugar de imponer un conjunto de "features" manuales.

A continuación se dispuso a formar los conjuntos de datos que usará el modelo. Hasta ahora se tienen datos para el entrenamiento del modelo y para la validación del mismo, sin embargo, no se tienen datos para realizar pruebas sobre el modelo resultante. Por lo tanto, se formará un nuevo conjunto de datos de pruebas a partir del cunjunto de entrenamiento, concretamente, seleccionando un 20\% de sus datos.

Para realizar esta tarea se recorre el directorio de datos de entrenamiento y aleatoriamente se seleccionan imágenes de cada subdirectorio (clase) y se añaden a un nuevo directorio que será el de datos de prueba.

Otra tarea importante en cuanto al procesado de los datos es normalizar los mismos. Para ello, se hace uso de \textit{ImageDatagenerator} de Tensorflow. Se usa esta función porque también sirve para aplicar la técnica de data augmentation en los datos de entrenamiento. Esta técnica consiste en generar datos adicionales a partir de los ya existentes aplicando transformaciones que mantienen la esencia de la información original, pero la presentan de manera distinta. Su objetivo principal es enriquecer el conjunto de entrenamiento para mejorar la capacidad de generalización del modelo resultante.

Es decir, a los tres conjuntos de datos se le apliza normalización que consiste en transformar los pixeles de cada imagen de valores que van de 0 a 255 (escala RGB) a valores entre 0 y 1. Además a las imágenes del conjunto de entrenamiento se le aplica la técnica de data augmentation que se ha mencionado anteriormente, concretamente se le aplican las siguientes transformaciones:

\begin{bulletlist}
\item Rota aleatoriamente la imagen hasta más menos 20 grados.
\item Aplica un zoom aleatorio entre 80\% y 120\% del tamaño original.
\item Desplaza la imagen horizontalmente hasta un 20\% de su ancho.
\item Desplaza la imagen verticalmente hasta un 20\% de su alto.
\item Aplica una transformación de cizallamiento (shear), como si se deformara la imagen en diagonal.
\item Gira horizontalmente las imágenes aleatoriamente.
\item Cambia el brillo aleatoriamente entre 80\% y 120\%.
\item Cuando una transformación (como una rotación o desplazamiento) deja espacios vacíos en la imagen, estos se rellenan con el valor del píxel más cercano.
\end{bulletlist}

Estas transformaciones se aplicarán aleatoriamente cada vez que el generador entrega un lote al modelo durante el entrenamiento. De esta manera, el modelo el modelo nunca verá dos veces exactamente la misma versión de la imagen.

Como ya se ha mencionado se ha usado \textit{ImageDatagenerator} para formar los conjuntos de datos. Concretamente lo que permite es crear generadores, que no son más que objetos que producen datos de forma incremental, lote a lote, en lugar de cargar todo el dataset en memoria de golpe. El generador se conecta a un directorio con datos y los va leyendo en lotes de un tamaño determinado, en este caso se ha usado un tamaño de 32, es decir, va formando lotes de 32 imágnes y a estas se les aplica normalización y también las transformaciones de data augmentation mencionadas si son datos de entrenamiento.

De esta manera, quedan los siguientes conjuntos de datos:

\begin{bulletlist}
\item Entrenamiento: Tiene 20.686 imágenes utilizadas para entrenar el modelo. Se trata de la mayor parte de los datos, ya que el modelo necesita muchos ejemplos para aprender patrones.
\item Validación: Tiene 6.683 imágenes. Estos datos se utilizan para evaluar el rendimiento del modelo durante el entrenamiento, sin afectar a los parámetros del modelo.
\item Prueba: Hay 5.165 imágenes para la prueba final. Este conjunto de datos se utiliza una vez finalizado el entrenamiento para medir objetivamente el rendimiento del modelo con datos nuevos que nunca se han visto.
\end{bulletlist}

Otro dato importante del conjunto de entrenamiento es el número de imágenes que se tiene por clase, ya que si hubiera muchas más imágenes de una clase que de otras, el modelo podría incluir un sesgo no deseado. El número de imágenes por clase del conjunto de entrenamiento es el siguiente:


\begin{table}[ht] 
\centering
\caption{\headlinecolor{\underline{Número de imágenes por clases en el conjunto de entrenamiento}}}
\label{tab:num_imagen_por_clase_entrenamiento}
\begin{tabular}{|c|c|} \hline
\rowcolor{naranja}
\multicolumn{2}{|c|}{\textbf{Número de imágenes por clases}} \\ \hline
\rowcolor{naranja!30}
Clase & N\textsuperscript{o} imágenes \\ \hline 
\texttt{Bacterial\_spot} & 2261 \\ \hline 
\texttt{Early\_blight} & 1964 \\ \hline 
\texttt{Late\_blight} & 2491 \\ \hline 
\texttt{Leaf\_Mold} & 2204 \\ \hline 
\texttt{Septoria\_leaf\_spot} & 2306 \\ \hline
\texttt{Spidermite\_Two-spotted\_spider\_mite} & 1398 \\ \hline
\texttt{Target\_Spot} & 1462 \\ \hline
\texttt{Tomato\_Yellow\_Leaf\_Curl\_Virus} & 1632 \\ \hline
\texttt{Tomato\_mosaic\_virus} & 1723 \\ \hline
\texttt{healthy} & 2441 \\ \hline
\texttt{powdery\_mildew} & 804 \\ \hline
\end{tabular}
\end{table}

La mayoría de clases tienen entre 2000 y 2400 imágenes, lo cual es aceptable. Sin embargo, existen clases claramente minoritarias, como \texttt{Spidermite\_Two-spotted\-\_spider\_mite} y \texttt{Target\_Spot} con menos de 1500 imágenes, o  \texttt{powdery\_mildew} con menos de 1000 imágenes. Esto puede causar que el modelo aprenda mejor las clases con más ejemplos y tienda a confundirse en las minoritarias porque tiene menos exposición a ellas.

Para evitar el posible problema de sesgo en el modelo se aplicará una técnica de balanceo al conjunto de entrenamiento. Específicamente se usará ponderación de clases con un diccionario \texttt{class\_weight} que se puede añadir al modelo en forma de parámetro. Esto dará más peso a los errores en clases minoritarias, para que el modelo no las ignore.

Los pesos de las clases se han calculado usando la función \texttt{compute\_class\_weight} que hace que las clases con menor muestras tengan mayor peso y las que tengan más muestras tengan menor peso. Haciendo, en promedio, que todas las clases tengan la misma importancia. Los pesos aplicados son los que se muestran a continuación:

\begin{table}[ht] 
\centering
\caption{\headlinecolor{\underline{Pesos asignados a cada clase en el entrenamiento del modelo}}}
\label{tab:pesos_por_clase_entrenamiento}
\begin{tabular}{|c|c|c|} \hline
\rowcolor{naranja}
\multicolumn{3}{|c|}{\textbf{Pesos por clases}} \\ \hline
\rowcolor{naranja!30}
Clase & N\textsuperscript{o} imágenes & Peso \\ \hline 
\texttt{Bacterial\_spot} & 2261 & 0.8317 \\ \hline 
\texttt{Early\_blight} & 1964 & 0.9575 \\ \hline 
\texttt{Late\_blight} & 2491 & 0.7549 \\ \hline 
\texttt{Leaf\_Mold} & 2204 & 0.8532 \\ \hline 
\texttt{Septoria\_leaf\_spot} & 2306 & 0.8155 \\ \hline
\texttt{Spidermite\_Two-spotted\_spider\_mite} & 1398 & 1.3451 \\ \hline
\texttt{Target\_Spot} & 1462 & 1.2862 \\ \hline
\texttt{Tomato\_Yellow\_Leaf\_Curl\_Virus} & 1632 & 1.1522 \\ \hline
\texttt{Tomato\_mosaic\_virus} & 1723 & 1.0914 \\ \hline
\texttt{healthy} & 2441 & 0.7703 \\ \hline
\texttt{powdery\_mildew} & 804 & 2.3389 \\ \hline
\end{tabular}
\end{table}


\section{Modelado}\label{sec:sec4.4}

En esta sección se describe la estrategia de modelado empleada, común a todos los experimentos realizados posteriormente. El enfoque adoptado se basa en el uso de redes neuronales convolucionales (CNN), dado que constituyen la arquitectura de referencia en tareas de clasificación de imágenes al ser capaces de extraer de manera automática y jerárquica características relevantes de los datos visuales.

Considerando las limitaciones de recursos computacionales disponibles, se optó por la técnica de transfer learning. Esta metodología permite aprovechar modelos previamente entrenados sobre grandes bases de datos, de modo que las capas iniciales ya contienen representaciones generales de las imágenes. Posteriormente, dichas representaciones se ajustan a la tarea específica de clasificación de enfermedades en hojas de tomate.

Concretamente se han usado los modelos \textit{MobileNetV2}, \textit{NASNetMobile} y \textit{EfficientNetB0} preentrenados con el dataset de ImageNet. De esta manera se aprovechan los pesos previamente aprendidos, que contienen representaciones visuales generales como bordes, texturas y formas, para inicializar la red. Posteriormente, esta red se adapta a la clasificación de enfermedades en hojas de tomate. 

Con el objetivo de gestionar mejor los recursos disponibles, se implementaron disitntos callbacks:

\begin{bulletlist}
\item HistorySaver: permite guardar el historial de métricas en un archivo externo. Esto resulta especialmente útil en entornos con recursos limitados o sesiones interrumpibles (como Google Colab), ya que garantiza que la información del entrenamiento no se pierda. Concretamente se ha usado para guardar las métricas de precisión y pérdida de entrenamiento y validación.
\item ModelCheckpoint: encargado de almacenar en disco el modelo con mejor desempeño en validación, según la métrica  de precisión (\texttt{val\_accuracy}). De este modo, se asegura la conservación de la mejor versión del modelo entrenado, evitando depender únicamente de los pesos finales.
\end{bulletlist}

Estos callbacks se han usado en todos los modelos. Sin embargo, en los llamados modelos optimizados se han usado otros dos callbacks:

\begin{bulletlist}
\item EarlyStopping: detiene el entrenamiento de forma anticipada si la pérdida de validación no mejora durante un número determinado de épocas consecutivas. Esto evita sobreentrenamiento y reduce el tiempo de cómputo innecesario.
\item ReduceLROnPlateau: ajusta de manera dinámica la tasa de aprendizaje cuando la pérdida de validación alcanza una meseta. Gracias a esta reducción progresiva, el modelo puede seguir afinando sus parámetros con pasos cada vez más pequeños, lo que mejora la convergencia.
\end{bulletlist}

En conjunto, estos callbacks permitieron no solo optimizar el uso de los recursos computacionales disponibles, sino también obtener modelos más robustos y con mejor capacidad de generalización.

Por último cabe destacar que para que los modelos puedan ser reconstruidos por cualquiera con acceso a los mismos datos de los que se parte es necesario fijar a un valor fijo disintas semillas aleatorias:

\begin{bulletlist}
\item Para la inicialización de los pesos en el modelo se usa \texttt{tf.random.set\_seed(42)}.
\item Para la generación de los conjuntos de datos con \textit{ImageDatagenerator} se usa el parámetro \texttt{seed} con valor 42.
\item Para el barajado de los datos del conjunto de entrenmaiento \texttt{random.seed(42)} y \texttt{np.random.seed(42)}.
\end{bulletlist}


\subsection{Modelo \textit{MobileNetV2}}\label{sec:sec4.4.1}

Este modelo usa de capa base \textit{MobileNetV2} preentrenada con los pesos de \textit{ImageNet}. Posteriormente se congelan las capas del modelo base para evitar que los pesos se modifiquen durante el entrenamiento y se use correctamente la técnica de \textit{transfer learning}. A continuación se añade una capa de \textit{GlobalAveragePooling} y una capa densa con 11 neuronas y función de activación \textit{softmax}, ya que nos enfrentamos a una clasificación de 11 clases.
Esta información es la que se muestra en la Figura \ref{fig:fig5}.

\begin{figure}[ht]
\begin{center}
\includegraphics[scale=0.7]{./Images/summary_mobilnetv2_1.png}
\caption{\headlinecolor{\underline{Resumen del modelo \textit{MobileNetV2} base 1}}}
\label{fig:fig5}
\end{center}
\end{figure}

Finalmente para la compilación se usa el optimizador Adam, la función de pérdida de entropía cruzada categórica y se escoge la métrica de precisión para evaluar el rendimiento. 

Se usa la función de pérdida de entropía cruzada categórica porque al crear los conjuntos de datos con ImageDatagenerator como se indica en la sessción \ref{sec:sec4.3} se usa el parámetro class mode con valor categorical que convierte las etiquetas a vectores one-hot encoded


\subsection{Modelo \textit{EfficientNetB0} base}\label{sec:sec4.4.2}

Este modelo usa de capa base \textit{EfficientNetB0} preentrenada con los pesos de ImageNet. Posteriormente se congelan las capas del modelo base para evitar que los pesos se modifiquen durante el entrenamiento y se use correctamente la técnica de transfer learning. A continuación se añade una capa de GlobalAveragePooling y una capa densa con 11 neuronas y función de activación softmax, ya que nos enfrentamos a una clasificación de 11 clases.
Finalmente par ala compilación se usa el optimizador Adam, la función de pérdida de entropía cruzada categórica y se escoge la métrica de precisión para evaluar el rendimiento.

Imagen de summary


\subsection{Modelo \textit{NASNetMobile} base}\label{sec:sec4.4.3}

Este modelo usa de capa base \textit{NASNetMobile} preentrenada con los pesos de ImageNet. Posteriormente se congelan las capas del modelo base para evitar que los pesos se modifiquen durante el entrenamiento y se use correctamente la técnica de transfer learning. A continuación se añade una capa de GlobalAveragePooling y una capa densa con 11 neuronas y función de activación softmax, ya que nos enfrentamos a una clasificación de 11 clases.
Finalmente par ala compilación se usa el optimizador Adam, la función de pérdida de entropía cruzada categórica y se escoge la métrica de precisión para evaluar el rendimiento.

Imagen de summary



\chapter{Evaluación y resultados}\label{cap:cap5}

En este capítulo se presentan los resultados obtenidos al usar los datos preprocesados explicado en la sección \ref{sec:sec4.3} a los modelos descritos en la sección \ref{sec:sec4.4}.


\section{Modelo \textit{MobileNetV2}}\label{sec:sec5.1}

En esta sección se van a mostrar los resultados del entrenamiento del modelo descrito en la subsección \ref{sec:sec4.4.1}. A este modelo se han aplicado varios entrenamientos distintos explicados en las subsecciones 5.1.1, 5.1.2 y 5.1.3


\subsection{Entrenamiento 1}\label{sec:sec5.1.1}

Este entrenamiento se ha realizado usando los pesos de clases descritos en la tabla x. Solo se ha sometido a 10 épocas y se han usado los callbacks de ModelCheckpoint e HistorySaver, ya que el objetivo de este entrenamiento es observar la tendencia inicial y poderlo comparar con el entrenamiento de la sección 5.1.2 para poder determinar qué tanto puede influir los pesos en las clases.

Para mostrar los resultados de este entrenamiento se va a comenzar mostrando las métricas recogidas en el fichero generado por el callback \textit{HistorySaver} en la Figura \ref{fig:fig6}.

\begin{figure}[ht]
\begin{center}
\includegraphics[scale=0.5]{./Images/historico_metricas_mobilenetv2_1.png}
\caption{\headlinecolor{\underline{Histórico de métricas del entrenamiento 1 del modelo \textit{MobileNetV2}}}}
\label{fig:fig6}
\end{center}
\end{figure}

En la Figura \ref{fig:fig6} podemos observar el comportamiento de las métricas de precisión y pérdida de entrenamiento y validación a lo largo de las épocas a las que se ha sometido el modelo descrito en la subsección \ref{sec:sec4.4.1} en el entrenamiento. A continuación se describe lo que se puede interpretar:  

\begin{bulletlist}
\item Precisión de entrenamiento: Comienza alrededor de 0.6 y sube rápidamente a un valor cercano a 0.9, mostrando que el modelo aprende bien de los datos de entrenamiento.
\item Pérdida de entrenamiento:
\item Precisión de validación:
\item Pérdida de validación:
\end{bulletlist}

\subsection{Entrenamiento 2}\label{sec:sec5.1.2}

Este entrenamiento es igual que el anterior, pero sin tener en cuenta los pesos de las clases.

Para mostrar los resultados de este entrenamiento se va a comenzar mostrando las métricas recogidas en el fichero generado por el callback \textit{HistorySaver} en la Figura \ref{fig:fig6}.

\begin{figure}[ht]
\begin{center}
\includegraphics[scale=0.5]{./Images/historico_metricas_mobilenetv2_1.png}
\caption{\headlinecolor{\underline{Histórico de métricas del modelo MobileNetV2 base 1}}}
\label{fig:fig7}
\end{center}
\end{figure}

En la Figura \ref{fig:fig7} podemos observar el comportamiento de las métricas de precisión y pérdida de entrenamiento y validación a lo largo de las épocas a las que se ha sometido el modelo descrito en la subsección \ref{sec:sec4.4.1} en el entrenamiento. A continuación se describe lo que se puede interpretar:  

\begin{bulletlist}
\item Precisión de entrenamiento: 
\item Pérdida de entrenamiento:
\item Precisión de validación:
\item Pérdida de validación:
\end{bulletlist}


Comparación con anterior modelo


\subsection{Entrenamiento 3}\label{sec:sec5.1.3}

Este entrenamiento es igual que el anterior, pero sin tener en cuenta los pesos de las clases.

Para mostrar los resultados de este entrenamiento se va a comenzar mostrando las métricas recogidas en el fichero generado por el callback \textit{HistorySaver} en la Figura \ref{fig:fig6}.

\begin{figure}[ht]
\begin{center}
\includegraphics[scale=0.5]{./Images/historico_metricas_mobilenetv2_1.png}
\caption{\headlinecolor{\underline{Histórico de métricas del modelo MobileNetV2 base 1}}}
\label{fig:fig8}
\end{center}
\end{figure}

En la Figura \ref{fig:fig7} podemos observar el comportamiento de las métricas de precisión y pérdida de entrenamiento y validación a lo largo de las épocas a las que se ha sometido el modelo descrito en la subsección \ref{sec:sec4.4.1} en el entrenamiento. A continuación se describe lo que se puede interpretar:  

\begin{bulletlist}
\item Precisión de entrenamiento: 
\item Pérdida de entrenamiento:
\item Precisión de validación:
\item Pérdida de validación:
\end{bulletlist}


\section{Modelo \textit{MobileNetV2} base 2}\label{sec:sec5.2}

En esta sección se van a mostrar los resultados del modelo descrito en el aprtado \ref{sec:sec4.4.2}. Para ello, en primer lugar se va a mostrar las métricas recogidas en el fichero generado por el callback HistorySaver en la Figura \ref{fig:fig5}.

\section{Modelo \textit{MobileNetV2} optimizado}\label{sec:sec5.3}

En esta sección se van a mostrar los resultados del modelo descrito en el aprtado \ref{sec:sec4.4.3}. Para ello, en primer lugar se va a mostrar las métricas recogidas en el fichero generado por el callback HistorySaver en la Figura \ref{fig:fig5}.


\begin{figure}[ht]
\begin{center}
\includegraphics[scale=0.7]{./Images/resumen_metricas_mobilenetv2_3.png}
\caption{\headlinecolor{\underline{Resumen de las métricas del modelo MobileNetV2 optimizado}}}
\label{fig:fig9}
\end{center}
\end{figure}

\begin{figure}[ht]
\begin{center}
\includegraphics[scale=0.5]{./Images/matriz_confusion_mobilenetv2_3.png}
\caption{\headlinecolor{\underline{Matriz de confusión del modelo MobileNetV2 optimizado}}}
\label{fig:fig10}
\end{center}
\end{figure}


\chapter{Conclusiones}\label{cap:cap6}

Se selecciona el mejor modelo y se muestra una gráfica probando el modelo (desarrollar)


\appendix
\chapter{Anexo I: Ejemplo de anexo}\label{cap:anexo1}
Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.

\begin{enumerate}[label=\bfseries\headlinecolor\arabic*.]
\item Primer elemento.
\item Segundo elemento
\item Tercer elemento.
\begin{enumerate}[label=\alph*)]
\item Primer subelemento.
\item Segundo subelemento.
\begin{itemize}[label=$\bullet$]
\item Primer punto.
\item Segundo punto.
\end{itemize}

\end{enumerate}

\end{enumerate}

\chapter{Anexo II: Otro ejemplo de anexo}\label{cap:anexo2}
Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.

Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.


\printbibliography

\end{document}
