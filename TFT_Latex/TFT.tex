\documentclass[12pt,a4paper]{scrreprt}

% Gráficos y geometría
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage[left=2.75cm,right=2.6cm,top=3.5cm,bottom=3.5cm]{geometry}


% Índices y listas
\usepackage{titletoc}
\usepackage[shortlabels]{enumitem}
\newlist{bulletlist}{itemize}{1} % Definición de una lista personalizada llamada "bulletlist"
\setlist[bulletlist]{label=\LARGE\textbullet, left=1.3em}


% Colores
\usepackage[table]{xcolor}
\definecolor{naranja}{HTML}{E65113}
\definecolor{slcolor}{HTML}{E65113}
\newcommand{\headlinecolor}{\color{slcolor}}
\definecolor{gray75}{gray}{0.75}


\newcommand{\hsp}{\hspace{-10pt}}

% URLs e hipervínculos
\usepackage{url}
\usepackage{hyperref}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%------------------COMANDOS PARA EL TIPO DE LETRA---------------------------%
\usepackage{fontspec}
\usepackage[T1]{fontenc}
\usepackage{helvet}
\renewcommand{\familydefault}{\sfdefault}

% Estilo de capítulos y secciones con KOMA-Script
\usepackage{xcolor}
\setkomafont{chapter}{\Huge\bfseries\headlinecolor}
\setkomafont{section}{\Large\bfseries}
\setkomafont{subsection}{\normalsize\bfseries}
\setkomafont{sectioning}{\bfseries}




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%-------------------COMANDOS PARA TABLAS  E IMAGENES ---------------------%
\usepackage{tikz}
\usepackage{tabularx}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%-----------------COMANDOS PARA CABECERAS Y PIE DE PAGINA -----------------%
\usepackage{lastpage}
\usepackage{fancyhdr}

\fancypagestyle{plain}{%
  \renewcommand{\headrulewidth}{0pt}
\fancyhead{}
\fancyfoot{}
\fancyfoot[R]{{\scriptsize\thepage\ de \pageref{LastPage} | Título del TFT}}
\fancyhead[L]{\tikz[remember picture,overlay]\node[opacity=0.4] at (-3mm, 10mm){\includegraphics[scale=0.18]{./Images/image3.png}};}
\fancyheadoffset{0pt}
}

\pagestyle{plain}


% Palabras clave
\providecommand{\keywords}[1]
{
  \small	
  \textbf{\textit{Palabras clave:\hspace{0.3cm}}} #1
}

% Bibliografía APA
%\usepackage[utf8]{inputenc} % no hace falta con xelatex
\usepackage[spanish]{babel} 
\usepackage{csquotes}
\usepackage[backend=biber, style=apa]{biblatex}
\addbibresource{Bibliografia_TFT.bib}

% Interlineado y espaciado entre párrafos
\usepackage{setspace}
\setstretch{1.2} % interlineado 1.3
\setlength{\parskip}{0.8em} % espacio entre párrafos



%%%%%%-------------------+++++++++--INICIO DEL DOCUMENTO--+++++++++---------------------------%%%%%

\begin{document}



%------------------XXXX++++++ INICIO DE PORTADA  ++++++XXXXX-----------------%
\begin{titlepage}

\newgeometry{left=2.5cm, bottom=3cm, top=2cm, right=2.5cm}

\tikz[remember picture,overlay] \node[opacity=1,inner sep=0pt] at (73.6mm, -124.25mm){\includegraphics{./Images/Picture_TitlePage.jpg}};

{\fontfamily{phv}\selectfont
%\fontsize{25}{10.4}\fontseries{b}\selectfont
\fontsize{25}{25}\fontseries{b}\selectfont
%\vspace{14cm}
\vspace{12cm}
\textbf{Desarrollo de un sistema de\\
diagnóstico de enfermedades\\
en hojas de tomate mediante\\ 
modelos de aprendizaje profundo}

\vfill

\fontsize{12}{12}\selectfont
\fontseries{m}\selectfont
\vspace{4cm}
\centering
\begin{tabularx}{1\textwidth} { 
  || >{\raggedright}X 
  || >{\centering}X 
  || >{\raggedleft\arraybackslash}X || }
 Titulación:\\Máster en Big Data y Ciencia de Datos\\ 
 & Alumno/a: Marín Lucas, Rubén\\DNI: 07272889-J 
 & Convocatoria: \\
 Curso Académico\\ 2024-2025 
  & Director/a del TFT: Ricardo Lebrón Aguilar   
  & SEGUNDA  \\
\end{tabularx}
 }
\end{titlepage}
%--------------------XXXX++++++ FIN DE PORTADA  ++++++XXXXX-----------------%
\tableofcontents	
\addcontentsline{toc}{chapter}{\listfigurename}
\addcontentsline{toc}{chapter}{\listtablename}
\listoffigures
\listoftables

\begin{abstract}
Lorem ipsum (RESUMEN)
\vspace{0.5cm}

\keywords{primero, segundo, tercero}
\end{abstract}
\newpage
\section*{Agradecimientos}\label{sec:agradecimientos}
Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.

	

\chapter{Introducción}\label{cap:cap1}

Tomate o tomatera (\textit{Solanum lycopersicum}) es una planta herbácea de la familia Solanaceae cultivada en todo el mundo para el cultivo de su fruto, el tomate o jitomate, uno de los ingredientes más universales de ensaladas y salsas en el mundo entero. \parencite{wikipedia1} 

Según los últimos estudios filogenéticos, la planta silvestre de la cual surge el tomate doméstico actual tiene origen en la zona andina del norte de Perú y sur de Ecuador. Su domesticación y diversificación posterior se originó en México.

Los pueblos aztecas y mayas lo usaban en su cocina y fue exportado al resto del mundo a partir de la llegada de los españoles que lo distribuyeron a lo largo de sus colonias en el Caribe y la península ibérica a partir de lo cual pudo llegar al resto de eruopa. También lo llevaron a Filipinas y de allí pudo entrar al continente asiático. \parencite{agrotendencia1} 

\begin{figure}[ht]
\begin{center}
\includegraphics[scale=0.15]{./Images/Distribucion_tomate.jpg}
\caption{\headlinecolor{\underline{Origen del tomate}}}

\label{fig:fig1}

\end{center}
\end{figure}

La producción mundial de tomate ascendió a más de 186 millones de toneladas en 2022 según los datos de la Organización de las Naciones Unidas para la Alimentación y la Agricultura (FAO). Según esta misma organización esta es la evolución de los 20 países que más han producido hasta 2022 es la mostrada en el Cuadro \ref{tab:producción_mundial_tomate}. \parencite{wikipedia2}

\begin{table}[ht] 
\centering
\caption{\headlinecolor{\underline{Top 20 países productores de tomates 2022}}}
\label{tab:producción_mundial_tomate}
\begin{tabular}{|c|c|c|c|c|} \hline
\rowcolor{naranja}
\multicolumn{5}{|c|}{\textbf{Titulo}} \\ \hline
\rowcolor{naranja!30}
País & 2000 & 2010 & 2020 & 2022 \\ \hline
China & 22 200 & 46 760 & 64 680 & 68 242 \\ \hline
India & 7430 & 12 433 & 20 550 & 20 694 \\ \hline
Turquía & 8890 & 10 052 & 13 204 & 13 000 \\ \hline
Estados Unidos & 12 622 & 14 053 & 10 939 & 10 200 \\ \hline
Egipto & 6786 & 8545 & 6494 & 6275 \\ \hline
Italia & 7538 & 6025 & 6248 & 6136 \\ \hline
México & 2666 & 2998 & 4137 & 4208 \\ \hline
Brasil & 3005 & 4107 & 3757 & 3810 \\ \hline
Nigeria & 1261 & 1800 & 3390 & 3685 \\ \hline
Esapaña & 3766 & 4313 & 4313 & 3652 \\ \hline
\end{tabular}
\end{table}

Como ya se ha mencionado, el cultivo de tomate es uno de los cultivos hortícolas más importantes a nivel mundial. Sin embargo, su producción se ve amenazada por una amplia variedad de enfermedades causadas por hongos, bacterias, virus y nematodos. Estas enfermedades pueden provocar una bajada de rendimiento que van desde reducciones parciales hasta la pérdida completa de la cosecha.

Entre las enfermedades más comunes se encuentran:

\begin{itemize}[label=\textbullet]
\item Tizón tardío (\textit{Phytophthora infestans}): Puede destruir por completo una plantación si no se controla a tiempo, especialmente en condiciones húmedas y templadas.

\begin{figure}[ht]
\begin{center}
\includegraphics[scale=0.4]{./Images/Tizon_tardio_tomate.jpg}
\caption{\headlinecolor{\underline{Tizón tardío en una planta de tomate}}}
\label{fig:fig2}
\end{center}
\end{figure}

\item Tizón temprano (\textit{Alternaria solani}): Produce defoliación progresiva, debilitando la planta y reduciendo el número y calidad de los frutos.

\begin{figure}[ht]
\begin{center}
\includegraphics[scale=0.2]{./Images/Tizon_temprano_tomate.jpg}
\caption{\headlinecolor{\underline{Tizón temprano en una planta de tomate}}}
\label{fig:fig3}
\end{center}
\end{figure}

\item Fusariosis vascular (\textit{Fusarium oxysporum}): Ataca el sistema vascular, provocando marchitez y muerte de plantas.
\item Virus como TYLCV y TSWV: Pueden causar deformaciones severas y reducciones completas en la producción, especialmente cuando se transmiten por vectores como la mosca blanca.
\end{itemize}

La manifestación simultánea o sucesiva de estas enfermedades es una de las principales causas en la disminución en la productividad del cultivo a escala global. Además, muchas de estas enfermedades no solo viven en la planta sino que persisten en el suelo, semillas o herramientas que hayan inteactuado con la planta, lo que dificulta su erradicación y aumenta los costos del tratamiento. \parencite{agrotendencia2}

Dada la magnitud del impacto de estas enfermedades, la detección temprana y precisa de las mismas es crucial. Permite una correcta intervención que minimiza las pérdidas, permitiendo la reducción del uso innecesario de los agroquímicos y mejorando la sostenibilidad. En este contexto, las tecnologías basadas en visión por computadora, sensores remotos e inteligencia artificial ofrecen soluciones eficaces para mejorar el seguimiento y el control sanitario de este cultivo clave.


\chapter{Objetivos}\label{cap:cap2}

El objetivo general de este proyecto consiste en conseguir un clasificador que a partir de imágenes de hojas de plantas de tomate distinga entre estado saludable y 10 enfermedades distintas.

\section{Objetivos específicos}\label{sec:sec2.1}

\begin{enumerate}[label=\bfseries\headlinecolor\arabic*.]
\item Analizar dataset de hojas de tomate.
\item Implementar y entrenar modelos CNN para la clasificación.
\item Evaluar la precisión de los modelos y comparar resultados.

\end{enumerate}


\chapter{Estado del arte}\label{cap:cap3}

En los últimos años la aplicación de técnicas de inteligencia artificial en la agricultura ha cobrado un papel relevante, especialmente en tareas de diagnóstico temprano de enfermedades en cultivos.  El uso de aprendizaje profundo permite automatizar la detección de patrones en imágenes, lo cual puede ayudar a los agricultores a tomar decisiones más rápidas y eficientes.

Inicialmente, los métodos empleados para esta tarea incluían algoritmos de aprendizaje supervisado como máquinas de vectores de soporte (SVM), k\-vecinos más cercanos (KNN) y redes bayesianas. Sin embargo, estos enfoques dependían en gran medida de una segmentación previa precisa y de la extracción manual de características, lo que limitaba su capacidad de generalización y precisión en entornos reales.

Con la llegada de las redes neuronales convolucionales (CNN), se ha producido un cambio significativo en la forma de abordar este problema. Las CNN son capaces de aprender representaciones directamente a partir de los datos de imagen, eliminando la necesidad de ingeniería manual de características. Diversos estudios han demostrado su eficacia para la clasificación de enfermedades en hojas de tomate.

Por ejemplo, una revisión publicada en la Revista de Investigación e Innovación de las Ciencias de la Universidad Tecnológica de Bolívar \parencite{estudio1}, las técnicas tradicionales de aprendizaje supervisado como SVM, KNN y lógica difusa muestran limitaciones significativas en tareas de detección de enfermedades en imágenes de frutas debido a su dependencia de extracción manual de características y segmentación previa. En contraste, las redes neuronales convolucionales han demostrado una precisión superior, mayor robustez frente a la variabilidad y mayor capacidad de generalización. Esta revisión respalda la elección de CNNs como enfoque principal en este trabajo.

Por otra parte, Valeria Maeda Gutiérrez (2019) \parencite{estudio2} realizó una comparativa entre varias arquitecturas CNN, incluyendo AlexNet, GoogleNet, InceptionV3, ResNet 18 y ResNet 50 aplicadas al conjunto de datos PlantVillage. Todas las arquitecturas consiguieron más del 98\% de precisión y sensibilidad, lo que confirma la ideonidad de las mismas para la tarea que se pretende hacer. Concretamente con GoogleNet consiguió una precisión del 99,3\% y una sensibilidad del 99,1\%

En otra línea, Eduardo A.Huerta-Mora, Víctor González-Huitrón, Héctor Rodríguez-Rangel y Leonel Ernesto Amabilis-Sosa (2024) \parencite{estudio3} emplearon la arquitectura VGG16 con técnicas de fine-tuning para el mismo conjunto de datos PlantVillage, obteniendo alrededor del 90\% de sensibilidad y precisión. Este hecho confirma que esta arquitectura también puede ser interesante para el estudia a realizar.


\chapter{Implementación y desarrollo}\label{cap:cap4}

En este capítulo se presenta tanto el \textit{hardware} como el \textit{software} usados en este proyecto. Además se explica la procedencia y estructura del conjunto de datos que serán usados para el estudio. Finalmente, se desarrolla el preprocesmiento que se realiza a este conjunto de datos junto con los modelos entrenados para conseguir un clasificador.

\section{Herramientas usadas}\label{sec:sec4.1}

Para llevar a cabo este proyecto, se ha usado Google Colab (abreviatura de Google Colaboratory) que se accedía desde el ordenador portátil del autor del documento. Este ordenador es un ASUS TUF Gaming FX505GT que cuenta con las siguientes características:

\begin{bulletlist}
\item 16 GB de RAM con formato DDR4.
\item Almacenamiento compuesto por un disco duro con tecnología SSD de 512GB.
\item Procesador Intel Core i7-9750H CPU a 2.60 GHz, con 6 procesadores principales y 6 procesadores lógicos.
\item Tarjeta gráfica NVIDIA GeForce GTX 1650 con 4GB de RAM.
\end{bulletlist}

Google Colab es un servicio gratuito de Google que permite escribir y ejecutar código en la nube sin necesidad de instalar nada en tu equipo. Los recursos que ofrece de forma gratuita varían con el tiempo, pero las características que suele ofrecer son las siguientes:

\begin{bulletlist}
\item GPU NVIDIA Tesla T4 con 16 GB de VRAM ó CPU Intel Xeon con alrededor de 13 GB de RAM.
\item Almacenamiento temporal se corresponde con unos 100 GB de espacio en disco.
\item La duración de la sesión puede ser de hasta 12 horas, aunque en la práctica podrían terminarse antes según uso y carga del sistema.
\end{bulletlist}

Por otra parte el lenguaje de programación usado ha sido Python, un lenguaje que es ampliamente utilizado por científicos de datos. En las últimas décadas Python se ha enriquecido con numerosas librerías relacionadas con técnicas de ML que facilitan el uso de las mismas. En concreto para este proyecto se ha utilizado la versión 3.12.11 de Python.

En cuanto a las librerías de Python usadas para la implementación, se presentan a continuación:

\begin{bulletlist}
\item NumPy: es una librería que ofrece la posibilidad de crear matrices y vectores multidimensionales y provee además un gran número de operaciones matemáticas de alto nivel.
\item Pandas: es una librería que ofrece la estructura de datos llamada DataFrame que facilita la manipulación y el análisis de datos. Es una extensión de la librería NumPy. Ha sido usada para tratar y transformar los datos.
\item Plantcv: es una librería de Python de código abierto diseñada específicamente para el análisis de imágenes de plantas. Se ha usado para lectura de las imágenes.
\item Tensorflow: es una librería de software de código abierto creada por Google para desarrollar y entrenar modelos de machine learning (ML) y deep learning (DL). Recibe este nombre porque trabaja con tensores, estructuras de datos multidimensionales, como matrices o vectores que fluyen a través de un grafo computacional de operaciones. Se ha usado para crear y entrenar los modelos descritos en este proyecto.
\item Seaborn: esta librería permite la visualización de los datos a través de distintos tipos de gráficas. Ha sido usada para realizar los distintos gráficos como las matrices de confusión para evaluar los modelos.
\item Sklearn: es una librería que contiene un gran número funciones relacionadas con modelos de machine learning (ML) y deep learning (DL). Se ha usado para extraer las principales métricas de los modelos tras su entrenamiento.
\end{bulletlist}


\section{Procedencia y descripción de los datos}\label{sec:sec4.2}

Los datos provienen de la plataforma online de ciencia de datos de Google, Kaggle, que funciona como una mezcla de red social, repositorio de datasets y espacio de competición. En concreto, el conjunto de datos usuado es el llamado "Tomato Leaves Dataset". Según su descripción en la misma plataforma se trata de un conjunto de datos de más de 20.000 imágenes de hojas de tomate con 11 clases, 10 enfermedades y una clase sana. Estas imágenes se han recopilado tanto en entornos de laboratorio como en entornos naturales. \parencite{kaggle}

En concreto se pueden extraer dos directorios que servirán como conjunto de datos para el entrenamiento y conjunto de datos para validación, ambos cuentan con 11 directorios con imágenes dentro. Cada uno de estos subdirectorios representa una de las clases que serán brevemente expuestas a continuación:

\begin{table}[ht] 
\centering
\caption{\headlinecolor{\underline{Clases del conjunto de datos}}}
\label{tab:clases_datos}
\begin{tabular}{|c|c|} \hline
\rowcolor{naranja}
\multicolumn{2}{|c|}{\textbf{Conjunto de datos}} \\ \hline
\rowcolor{naranja!30}
Clase & Traducción Clase \\ \hline 
\texttt{Healthy} & Saludable \\ \hline 
\texttt{Bacterial\_spot} & Manchas bacterianas \\ \hline 
\texttt{Early\_blight} & Tizón precoz \\ \hline 
\texttt{Late\_blight} & Tizón tardío \\ \hline 
\texttt{Leaf\_Mold} & Hojas con moho \\ \hline 
\texttt{Powdery\_mildew} & Moho polvoriento \\ \hline 
\texttt{Septoria\_leaf\_spot} & Hojas manchadas de septoriosis \\ \hline 
\texttt{Spidermite\_Two-spotted\_spider\_mite} & Picadura de araña roja de dos manchas \\ \hline 
\texttt{Target\_Spot} & Punto blanco \\ \hline 
\texttt{Tomato\_mosaic\_virus} & Virus mosaico \\ \hline 
\texttt{Tomato\_Yellow\_Leaf\_Curl\_Virus} & Virus de la hoja amarilla \\ \hline
\end{tabular}
\end{table}


\section{Preprocesado de los datos}\label{sec:sec4.3}

Al realizar la carga de datos se tiene un directorio con dos subdirectorios, cada uno de ellos representará un conjunto de datos, uno de datos de entrenamiento (\textit{train}) y otro de validación (\textit{valid}). Cada uno de estos directorios contienen a su vez 11 directorios, representando cada una de las clases. 

A continuación, se llevan a cabo las primeras tareas de exploración de las imágenes.

En primer lugar, seleccionando el directorio que contiene los datos de entrenamiento se realiza una función para obtener el número de imágenes existentes por cada tipo de tamaño. Gracias a esta función se sabe que se cuentan con imágenes de variables tamaños, concretamente existen 760 tipos de tamaños distintos. En la siguiente tabla se exponen los 5 tipos de tamaño que más se repiten:

\begin{table}[ht] 
\centering
\caption{\headlinecolor{\underline{Los 5 tamaños de imágenes más comunes}}}
\label{tab:tamanos_imagenes}
\begin{tabular}{|c|c|} \hline
\rowcolor{naranja}
\multicolumn{2}{|c|}{\textbf{Top 5 tamaños de imágenes}} \\ \hline
\rowcolor{naranja!30}
Tamaño (píxeles) & N\textsuperscript{o} imágenes \\ \hline 
256x256 & 18942 \\ \hline 
227x227 & 4120 \\ \hline 
640x640 & 1207 \\ \hline 
533x800 & 151 \\ \hline 
800x600 & 10 \\ \hline
\end{tabular}
\end{table}

De cara a construir un modelo todas las imágenes tienen que tener el mismo tamaño y debida a esta primera toma de contacto se toma la decisión de transformar todas las imágenes a tamaño de 256x256 píxeles. Sin embargo, debido a los modelos usados se termina convirtiendo a imágenes de tamaño 224x224, ya que es un tamañao estándar que entiende cualquier modelo y es el más cercano a los dos tipo de tamños de imágenes más usuales en nuestros datos.

En segundo lugar, se realiza una muestra aleatoria de una imagen por clase, para visualizar el tipo de imágenes que se van a tratar en la Figura \ref{fig:fig4}.

\begin{figure}[ht]
\begin{center}
\includegraphics[scale=0.35]{./Images/Imagen_aleatoria_por_clase.png}
\caption{\headlinecolor{\underline{Imagen aleatoria por clase}}}
\label{fig:fig4}
\end{center}
\end{figure}

En la Figura \ref{fig:fig4} se puede observar la gran variedad de imágenes que existen, con distintos brillos, distintos fondos o incluso giradas:

\begin{bulletlist}
\item En cuanto al brillo se puede observar que la imagen de \texttt{Target\_Spot} tiene mucho más brillo que la de \texttt{Tomato\_Yellow\_Leaf\_Curl\_Virus}.
\item Con respecto al fondo podemos vir distinciones entre la imagen \texttt{Bacterial\_spot} con un fondo grisáceo plano, la imagen \texttt{Late\_blight} con fondo completamente negro y la foto \texttt{Early\_blight} en la que se ve el resto de la planta de tomate, no solo se ve una hoja.
\item También se puede destacar la diferencia entre las posiciones de las hojas, algunas como \texttt{Bacterial\_spot} tienen el tallo abajo, otras como \texttt{Leaf\_Mold} tienen el tallo arriba y otras como \texttt{Septoria\_leaf\_spot} tienen el tallo horizontal. 
\item Además se tiene un ejemplo de imagen rotada, concretamente la \texttt{Septoria\-\_leaf\_spot}
\end{bulletlist}

Debido a esta gran variedad de imágenes y de enfermedades se llegó a la conclusión de que no tiene mucho sentido usar funciones especiales de la librería PlantCV, ya que esta está muy orientada al fenotipado clásico (área, forma, color, índices), y esas características a veces no capturan la complejidad de patrones de enfermedades, que suelen ser más sutiles y no lineales. La estrategia que se ha seguido es pasar a un pipeline de deep learning con imágenes preprocesadas de forma estándar. De esta manera el modelo aprenderá por si mismo las características discriminantes en lugar de imponer un conjunto de \textit{features} manuales.

A continuación se dispuso a formar los conjuntos de datos que usará el modelo. Hasta ahora se tienen datos para el entrenamiento del modelo y para la validación del mismo, sin embargo, no se tienen datos para realizar pruebas sobre el modelo resultante. Por lo tanto, se formará un nuevo conjunto de datos de pruebas a partir del cunjunto de entrenamiento, concretamente, seleccionando un 20\% de sus datos.

Para realizar esta tarea se recorre el directorio de datos de entrenamiento y aleatoriamente se seleccionan imágenes de cada subdirectorio (clase) y se añaden a un nuevo directorio que será el de datos de prueba.

Otra tarea importante en cuanto al procesado de los datos es normalizar los mismos. Para ello, se hace uso de \textit{ImageDatagenerator} de Tensorflow. Se usa esta función porque también sirve para aplicar la técnica de data augmentation en los datos de entrenamiento. Esta técnica consiste en generar datos adicionales a partir de los ya existentes aplicando transformaciones que mantienen la esencia de la información original, pero la presentan de manera distinta. Su objetivo principal es enriquecer el conjunto de entrenamiento para mejorar la capacidad de generalización del modelo resultante.

Es decir, a los tres conjuntos de datos se le apliza normalización que consiste en transformar los pixeles de cada imagen de valores que van de 0 a 255 (escala RGB) a valores entre 0 y 1. Además a las imágenes del conjunto de entrenamiento se le aplica la técnica de data augmentation que se ha mencionado anteriormente, concretamente se le aplican las siguientes transformaciones:

\begin{bulletlist}
\item Rota aleatoriamente la imagen hasta más menos 20 grados.
\item Aplica un zoom aleatorio entre 80\% y 120\% del tamaño original.
\item Desplaza la imagen horizontalmente hasta un 20\% de su ancho.
\item Desplaza la imagen verticalmente hasta un 20\% de su alto.
\item Aplica una transformación de cizallamiento (shear), como si se deformara la imagen en diagonal.
\item Gira horizontalmente las imágenes aleatoriamente.
\item Cambia el brillo aleatoriamente entre 80\% y 120\%.
\item Cuando una transformación (como una rotación o desplazamiento) deja espacios vacíos en la imagen, estos se rellenan con el valor del píxel más cercano.
\end{bulletlist}

Estas transformaciones se aplicarán aleatoriamente cada vez que el generador entrega un lote al modelo durante el entrenamiento. De esta manera, el modelo el modelo nunca verá dos veces exactamente la misma versión de la imagen.

Como ya se ha mencionado se ha usado \textit{ImageDatagenerator} para formar los conjuntos de datos. Concretamente lo que permite es crear generadores, que no son más que objetos que producen datos de forma incremental, lote a lote, en lugar de cargar todo el dataset en memoria de golpe. El generador se conecta a un directorio con datos y los va leyendo en lotes de un tamaño determinado, en este caso se ha usado un tamaño de 32, es decir, va formando lotes de 32 imágnes y a estas se les aplica normalización y también las transformaciones de data augmentation mencionadas si son datos de entrenamiento.

De esta manera, quedan los siguientes conjuntos de datos:

\begin{bulletlist}
\item Entrenamiento: Tiene 20.686 imágenes utilizadas para entrenar el modelo. Se trata de la mayor parte de los datos, ya que el modelo necesita muchos ejemplos para aprender patrones.
\item Validación: Tiene 6.683 imágenes. Estos datos se utilizan para evaluar el rendimiento del modelo durante el entrenamiento, sin afectar a los parámetros del modelo.
\item Prueba: Hay 5.165 imágenes para la prueba final. Este conjunto de datos se utiliza una vez finalizado el entrenamiento para medir objetivamente el rendimiento del modelo con datos nuevos que nunca se han visto.
\end{bulletlist}

Otro dato importante del conjunto de entrenamiento es el número de imágenes que se tiene por clase, ya que si hubiera muchas más imágenes de una clase que de otras, el modelo podría incluir un sesgo no deseado. El número de imágenes por clase del conjunto de entrenamiento es el siguiente:


\begin{table}[ht] 
\centering
\caption{\headlinecolor{\underline{Número de imágenes por clases en el conjunto de entrenamiento}}}
\label{tab:num_imagen_por_clase_entrenamiento}
\begin{tabular}{|c|c|} \hline
\rowcolor{naranja}
\multicolumn{2}{|c|}{\textbf{Número de imágenes por clases}} \\ \hline
\rowcolor{naranja!30}
Clase & N\textsuperscript{o} imágenes \\ \hline 
\texttt{Bacterial\_spot} & 2261 \\ \hline 
\texttt{Early\_blight} & 1964 \\ \hline 
\texttt{Late\_blight} & 2491 \\ \hline 
\texttt{Leaf\_Mold} & 2204 \\ \hline 
\texttt{Septoria\_leaf\_spot} & 2306 \\ \hline
\texttt{Spidermite\_Two-spotted\_spider\_mite} & 1398 \\ \hline
\texttt{Target\_Spot} & 1462 \\ \hline
\texttt{Tomato\_Yellow\_Leaf\_Curl\_Virus} & 1632 \\ \hline
\texttt{Tomato\_mosaic\_virus} & 1723 \\ \hline
\texttt{healthy} & 2441 \\ \hline
\texttt{powdery\_mildew} & 804 \\ \hline
\end{tabular}
\end{table}

La mayoría de clases tienen entre 2000 y 2400 imágenes, lo cual es aceptable. Sin embargo, existen clases claramente minoritarias, como \texttt{Spidermite\_Two-spotted\-\_spider\_mite} y \texttt{Target\_Spot} con menos de 1500 imágenes, o  \texttt{powdery\_mildew} con menos de 1000 imágenes. Esto puede causar que el modelo aprenda mejor las clases con más ejemplos y tienda a confundirse en las minoritarias porque tiene menos exposición a ellas.

Para evitar el posible problema de sesgo en el modelo se aplicará una técnica de balanceo al conjunto de entrenamiento. Específicamente se usará ponderación de clases con un diccionario \texttt{class\_weight} que se puede añadir al modelo en forma de parámetro. Esto dará más peso a los errores en clases minoritarias, para que el modelo no las ignore.

Los pesos de las clases se han calculado usando la función \texttt{compute\_class\_weight} que hace que las clases con menor muestras tengan mayor peso y las que tengan más muestras tengan menor peso. Haciendo, en promedio, que todas las clases tengan la misma importancia. Los pesos aplicados son los que se muestran a continuación:

\begin{table}[ht] 
\centering
\caption{\headlinecolor{\underline{Pesos asignados a cada clase en el entrenamiento del modelo}}}
\label{tab:pesos_por_clase_entrenamiento}
\begin{tabular}{|c|c|c|} \hline
\rowcolor{naranja}
\multicolumn{3}{|c|}{\textbf{Pesos por clases}} \\ \hline
\rowcolor{naranja!30}
Clase & N\textsuperscript{o} imágenes & Peso \\ \hline 
\texttt{Bacterial\_spot} & 2261 & 0.8317 \\ \hline 
\texttt{Early\_blight} & 1964 & 0.9575 \\ \hline 
\texttt{Late\_blight} & 2491 & 0.7549 \\ \hline 
\texttt{Leaf\_Mold} & 2204 & 0.8532 \\ \hline 
\texttt{Septoria\_leaf\_spot} & 2306 & 0.8155 \\ \hline
\texttt{Spidermite\_Two-spotted\_spider\_mite} & 1398 & 1.3451 \\ \hline
\texttt{Target\_Spot} & 1462 & 1.2862 \\ \hline
\texttt{Tomato\_Yellow\_Leaf\_Curl\_Virus} & 1632 & 1.1522 \\ \hline
\texttt{Tomato\_mosaic\_virus} & 1723 & 1.0914 \\ \hline
\texttt{healthy} & 2441 & 0.7703 \\ \hline
\texttt{powdery\_mildew} & 804 & 2.3389 \\ \hline
\end{tabular}
\end{table}


\section{Modelado}\label{sec:sec4.4}

En esta sección se describe la estrategia de modelado empleada, común a todos los experimentos realizados posteriormente. El enfoque adoptado se basa en el uso de redes neuronales convolucionales (CNN), dado que constituyen la arquitectura de referencia en tareas de clasificación de imágenes al ser capaces de extraer de manera automática y jerárquica características relevantes de los datos visuales.

Considerando las limitaciones de recursos computacionales disponibles, se optó por la técnica de transfer learning. Esta metodología permite aprovechar modelos previamente entrenados sobre grandes bases de datos, de modo que las capas iniciales ya contienen representaciones generales de las imágenes. Posteriormente, dichas representaciones se ajustan a la tarea específica de clasificación de enfermedades en hojas de tomate.

Concretamente se han usado los modelos \textit{MobileNetV2}, \textit{NASNetMobile} y \textit{EfficientNetB0} preentrenados con el dataset de \textit{ImageNet}. De esta manera se aprovechan los pesos previamente aprendidos, que contienen representaciones visuales generales como bordes, texturas y formas, para inicializar la red. Posteriormente, esta red se adapta a la clasificación de enfermedades en hojas de tomate. 

Con el objetivo de gestionar mejor los recursos disponibles, se implementaron disitntos callbacks:

\begin{bulletlist}
\item \textit{HistorySaver}: permite guardar el historial de métricas en un archivo externo. Esto resulta especialmente útil en entornos con recursos limitados o sesiones interrumpibles (como Google Colab), ya que garantiza que la información del entrenamiento no se pierda. Concretamente se ha usado para guardar las métricas de precisión y pérdida de entrenamiento y validación.
\item \textit{ModelCheckpoint}: encargado de almacenar en disco el modelo con mejor desempeño en validación, según la métrica  de precisión (\texttt{val\_accuracy}). De este modo, se asegura la conservación de la mejor versión del modelo entrenado, evitando depender únicamente de los pesos finales.
\end{bulletlist}

Estos callbacks se han usado en todos los entrenamientos. Sin embargo, en algunos entrenamientos se han usado además otros dos callbacks:

\begin{bulletlist}
\item \textit{EarlyStopping}: detiene el entrenamiento de forma anticipada si la pérdida de validación no mejora durante un número determinado de épocas consecutivas. Esto evita sobreentrenamiento y reduce el tiempo de cómputo innecesario.
\item \textit{ReduceLROnPlateau}: ajusta de manera dinámica la tasa de aprendizaje cuando la pérdida de validación alcanza una meseta. Gracias a esta reducción progresiva, el modelo puede seguir afinando sus parámetros con pasos cada vez más pequeños, lo que mejora la convergencia.
\end{bulletlist}

En conjunto, estos callbacks permitieron no solo optimizar el uso de los recursos computacionales disponibles, sino también obtener modelos más robustos y con mejor capacidad de generalización.

Por último cabe destacar que para que los modelos puedan ser reconstruidos por cualquiera con acceso a los mismos datos de los que se parte es necesario fijar a un valor fijo disintas semillas aleatorias:

\begin{bulletlist}
\item Para la inicialización de los pesos en el modelo se usa \texttt{tf.random.set\_seed(42)}.
\item Para la generación de los conjuntos de datos con \textit{ImageDatagenerator} se usa el parámetro \texttt{seed} con valor 42.
\item Para el barajado de los datos del conjunto de entrenmaiento \texttt{random.seed(42)} y \texttt{np.random.seed(42)}.
\end{bulletlist}


\subsection{Modelo \textit{MobileNetV2}}\label{sec:sec4.4.1}

Este modelo usa de capa base \textit{MobileNetV2} preentrenada con los pesos de \textit{ImageNet}. Posteriormente se congelan las capas del modelo base para evitar que los pesos se modifiquen durante el entrenamiento y se use correctamente la técnica de \textit{transfer learning}. A continuación se añade una capa de \textit{GlobalAveragePooling} y una capa densa con 11 neuronas y función de activación \textit{softmax}, ya que nos enfrentamos a una clasificación de 11 clases.
Esta información es la que se muestra en la Figura \ref{fig:fig5}.

\begin{figure}[ht]
\begin{center}
\includegraphics[scale=0.7]{./Images/summary_mobilnetv2_1.png}
\caption{\headlinecolor{\underline{Resumen del modelo \textit{MobileNetV2}}}}
\label{fig:fig5}
\end{center}
\end{figure}

Finalmente para la compilación se usa el optimizador Adam, la función de pérdida de entropía cruzada categórica y se escoge la métrica de precisión para evaluar el rendimiento. 

Se usa la función de pérdida de entropía cruzada categórica porque al crear los conjuntos de datos con ImageDatagenerator como se indica en la sessción \ref{sec:sec4.3} se usa el parámetro class mode con valor categorical que convierte las etiquetas a vectores one-hot encoded


\subsection{Modelo \textit{EfficientNetB0}}\label{sec:sec4.4.2}

Este modelo usa de capa base \textit{EfficientNetB0} preentrenada con los pesos de \textit{ImageNet}. Posteriormente se congelan las capas del modelo base para evitar que los pesos se modifiquen durante el entrenamiento y se use correctamente la técnica de \textit{transfer learning}. A continuación se añade una capa de \textit{GlobalAveragePooling} y una capa densa con 11 neuronas y función de activación \textit{softmax}, ya que nos enfrentamos a una clasificación de 11 clases.
Esta información es la que se muestra en la Figura \ref{fig:fig6}.

\begin{figure}[ht]
\begin{center}
\includegraphics[scale=0.7]{./Images/summary_efficientnetb0_1.png}
\caption{\headlinecolor{\underline{Resumen del modelo \textit{EfficientNetB0}}}}
\label{fig:fig6}
\end{center}
\end{figure}

Finalmente para la compilación se usa el optimizador Adam, la función de pérdida de entropía cruzada categórica y se escoge la métrica de precisión para evaluar el rendimiento. 


\subsection{Modelo \textit{NASNetMobile}}\label{sec:sec4.4.3}

Este modelo usa de capa base \textit{NASNetMobile} preentrenada con los pesos de ImageNet. Posteriormente se congelan las capas del modelo base para evitar que los pesos se modifiquen durante el entrenamiento y se use correctamente la técnica de \textit{transfer learning}. A continuación se añade una capa de \textit{GlobalAveragePooling} y una capa densa con 11 neuronas y función de activación \textit{softmax}, ya que nos enfrentamos a una clasificación de 11 clases.
Esta información es la que se muestra en la Figura \ref{fig:fig7}.

\begin{figure}[ht]
\begin{center}
\includegraphics[scale=0.7]{./Images/summary_nasnetmobile_1.png}
\caption{\headlinecolor{\underline{Resumen del modelo \textit{NASNetMobile}}}}
\label{fig:fig7}
\end{center}
\end{figure}

Finalmente para la compilación se usa el optimizador Adam, la función de pérdida de entropía cruzada categórica y se escoge la métrica de precisión para evaluar el rendimiento. 


\chapter{Evaluación y resultados}\label{cap:cap5}

En este capítulo se presentan los resultados obtenidos al usar los datos preprocesados explicado en la sección \ref{sec:sec4.3} a los modelos descritos en la sección \ref{sec:sec4.4}.


\section{Modelo \textit{MobileNetV2}}\label{sec:sec5.1}

En esta sección se van a mostrar los resultados del entrenamiento del modelo descrito en la subsección \ref{sec:sec4.4.1}. A este modelo se han aplicado varios entrenamientos distintos explicados en las subsecciones \ref{sec:sec5.1.1}, \ref{sec:sec5.1.2} y \ref{sec:sec5.1.3}.


\subsection{Entrenamiento 1}\label{sec:sec5.1.1}

Este entrenamiento se ha realizado usando los pesos de clases descritos en el Cuadro \ref{tab:pesos_por_clase_entrenamiento}. Solo se ha sometido a 10 épocas y se han usado los callbacks de \textit{ModelCheckpoint} e \textit{HistorySaver}, ya que el objetivo de este entrenamiento es observar la tendencia inicial para poderlo comparar con el entrenamiento de la sección \ref{sec:sec5.1.2} y poder determinar qué tanto puede influir los pesos en las clases.

Para mostrar los resultados de este entrenamiento se va a comenzar mostrando las métricas recogidas en el fichero generado por el callback \textit{HistorySaver} en la Figura \ref{fig:fig8}.

\begin{figure}[ht]
\begin{center}
\includegraphics[scale=0.5]{./Images/historico_metricas_mobilenetv2_1.png}
\caption{\headlinecolor{\underline{Histórico de métricas del entrenamiento 1 del modelo \textit{MobileNetV2}}}}
\label{fig:fig8}
\end{center}
\end{figure}

En esta figura se puede observar el comportamiento de las métricas de precisión y pérdida de entrenamiento y validación a lo largo de las épocas a las que se ha sometido el modelo descrito en la subsección \ref{sec:sec4.4.1} en el entrenamiento. A continuación se describe lo que se puede interpretar:  

\begin{bulletlist}
\item Precisión de entrenamiento: Comienza alrededor de 0.6 y sube rápidamente a un valor cercano a 0.8, mostrando que el modelo aprende bien de los datos de entrenamiento.
\item Pérdida de entrenamiento: Disminuye de un valor cercano a 1 hasta cerca de 0.6, lo que confirma que el modelo está optimizando correctamente con la función de pérdida elegida para los datos de entrenamiento.
\item Precisión de validación: Aumenta de un valor cercano a 0.7 a un valor cercano a 0.8, lo que muestra que el modelo aprende bien de datos distintos a los de entrenamiento.
\item Pérdida de validación: Disminuye de un valor cercano a 0.8 a un valor cercano a 0.5, confirmando que la función de pérdida optimiza bien el modelo.
\end{bulletlist}

En resumen, ambas métricas de precisión tienden a subir acercándose a 1 y las métricas de pérdidas a bajar acercándose a 0. Ambas tendencias se realizan de manera progresiva sin señales de \textit{overfitting}. 

La precisión de entrenamiento se estabiliza alrededor de 0.8, con incrementos pequeños al final. Esto puede indicar que el modelo se está acercando a su límite de capacidad con la configuración actual. Para exprimir aún más este modelo con intención de mejorarlo se podría aumentar el número de épocas con el callback \textit{EarlyStopping} para que pare el entrenamiento en caso de que no mejore y el callback de \textit{ReduceLROnPlateau} para que reduzca el \textit{learning rate} en el entrenamiento y haga que no se estanquen sus valores. 

Para poder comparar este entrenamiento con el de la subsección \ref{sec:sec5.1.2} es necesario realizar un análisis de métricas por clases. Para ello se van a mostrar las métricas del método \texttt{classification\_report} de la librería \textit{Sklearn} en la Figura \ref{fig:fig9} y la matriz de confusión en la Figura \ref{fig:fig10}.

\begin{figure}[ht]
\begin{center}
\includegraphics[scale=0.7]{./Images/resumen_metricas_mobilenetv2_1.png}
\caption{\headlinecolor{\underline{Resumen de métricas del modelo \textit{MobileNetV2} en el entrenamiento 1}}}
\label{fig:fig9}
\end{center}
\end{figure}

\begin{figure}[ht]
\begin{center}
\includegraphics[scale=0.5]{./Images/matriz_confusion_mobilenetv2_1.png}
\caption{\headlinecolor{\underline{Matriz de confusión del modelo \textit{MobileNetV2} en el entrenamiento 1}}}
\label{fig:fig10}
\end{center}
\end{figure}

Para entender las métricas de la Figura \ref{fig:fig9} se va a hacer una breve explicación de cada una de ellas:

\begin{bulletlist}
\item Precisión (\textit{Precision}): De todas las imágenes que el modelo predijo como una clase, cuántas realmente pertenecen a esa clase.
\item Sensibilidad (\textit{Recall}): De todas las imágenes que son realmente de una clase, cuántas fueron detectadas correctamente.
\item \textit{F1-Score}: Es el promedio armónico entre precisión y sensibilidad.
\item Soporte (\textit{Support}): El número de imágenes reales de cada clase en el conjunto de test.
\end{bulletlist}

Sabiendo esto se puede decir que el modelo tiene un rendimiento homogéneo entre clases habiendo un balance bastante bueno entre precisión y sensibilidad en practicamente todas las clases.

Para extraer resultados de la Figura \ref{fig:fig10} se va a explicar qué es una matriz de confusión.  Una matriz de confusión es una herramienta que permite la visualización del desempeño de un modelo de clasificación. Cada columna representa el número de predicciones de cada clase, mientras que cada fila representa a las instancias en la clase real.

De esta manera se puede afirmar que:

\begin{bulletlist}
\item Las clases \texttt{Tomato\_Yellow\_Leaf\_Curl\_Virus}, \texttt{Tomato\_mosaic\_virus} y \texttt{healthy} son clasificadas casi a la perfección. Cuando nuestro modelo predice esas clases tiene una tas de acierto mayor al 90\%.
\item Las clases \texttt{Target\_Spot}, \texttt{powdery\_mildew}, \texttt{Early\_blight} y \texttt{Septoria\_leaf\_spot} son las más conflictivas, ya que el modelo tiende a clasificar otras imágenes como ellas.
\end{bulletlist}

Este modelo tiene un comportamiento sólido y equilibrado, generaliza bien y consigue que incluso las clases con menos muestras tengan buenos niveles de recall. 


\subsection{Entrenamiento 2}\label{sec:sec5.1.2}

Este entrenamiento es igual que el anterior, pero sin tener en cuenta los pesos de las clases.

Para mostrar los resultados de este entrenamiento se va a comenzar mostrando las métricas recogidas en el fichero generado por el callback \textit{HistorySaver} en la Figura \ref{fig:fig10}.

\begin{figure}[ht]
\begin{center}
\includegraphics[scale=0.5]{./Images/historico_metricas_mobilenetv2_2.png}
\caption{\headlinecolor{\underline{Histórico de métricas del entrenamiento 2 del modelo \textit{MobileNetV2}}}}
\label{fig:fig11}
\end{center}
\end{figure}

En la Figura \ref{fig:fig11} podemos observar el comportamiento de las métricas de precisión y pérdida de entrenamiento y validación a lo largo de las épocas a las que se ha sometido el modelo descrito en la subsección \ref{sec:sec4.4.1} en el entrenamiento. A continuación se describe lo que se puede interpretar:  

\begin{bulletlist}
\item Precisión de entrenamiento: Comienza alrededor de 0.6 y sube rápidamente a un valor cercano a 0.8, mostrando que el modelo aprende bien de los datos de entrenamiento.
\item Pérdida de entrenamiento: Disminuye de un valor cercano a 1 hasta cerca de 0.6, lo que confirma que el modelo está optimizando correctamente con la función de pérdida elegida para los datos de entrenamiento.
\item Precisión de validación: Aumenta de un valor cercano a 0.7 a un valor cercano a 0.8, lo que muestra que el modelo aprende bien de datos distintos a los de entrenamiento.
\item Pérdida de validación: Disminuye de un valor cercano a 0.8 a un valor cercano a 0.5, confirmando que la función de pérdida optimiza bien el modelo.
\end{bulletlist}

En resumen, ambas métricas de precisión tienden a subir acercándose a 1 y las métricas de pérdidas a bajar acercándose a 0. Ambas tendencias se realizan de manera progresiva sin señales de \textit{overfitting}. 

El rendimiento global es prácticamente el mismo que el conseguido con el entrenmaiento de la subsección \ref{sec:sec5.1.1}, por lo que para poder compararlos más detalladamente es necesario realizar un análisis de métricas por clases. Para ello se van a mostrar las métricas del método \texttt{classification\_report} de la librería \textit{Sklearn} en la Figura \ref{fig:fig12} y la matriz de confusión en la Figura \ref{fig:fig13}.

\begin{figure}[ht]
\begin{center}
\includegraphics[scale=0.7]{./Images/resumen_metricas_mobilenetv2_2.png}
\caption{\headlinecolor{\underline{Resumen de métricas del modelo \textit{MobileNetV2} en el entrenamiento 2}}}
\label{fig:fig12}
\end{center}
\end{figure}

\begin{figure}[ht]
\begin{center}
\includegraphics[scale=0.5]{./Images/matriz_confusion_mobilenetv2_2.png}
\caption{\headlinecolor{\underline{Matriz de confusión del modelo \textit{MobileNetV2} en el entrenamiento 2}}}
\label{fig:fig13}
\end{center}
\end{figure}

En general se obtiene un buen rendimiento, existiendo un buen balance entre precisión y sensibilidad en practicamente todas las clases. Aún así, se pueden observar diferencias en algunas clases con respecto al modelo resultante de la subsección \ref{sec:sec5.1.1}. En concreto se puede determinar una disminución en la métrica de sensibilidad en en clases menos representadas en el dataset como las clases \texttt{powdery\_mildew} (de 0.93 a 0.80), \texttt{Septoria\_leaf\_spot} (de 0.71 a 0.61) y \texttt{Spidermite\_Two-spotted\_\-spider\_mite} (de 0.84 a 0.70).

En cuanto a los resultados de la Figura \ref{fig:fig13} son bastantes similares a los de la subsección \ref{sec:sec5.1.1}

\begin{bulletlist}
\item Las clases \texttt{Tomato\_Yellow\_Leaf\_Curl\_Virus}, \texttt{Tomato\_mosaic\_virus} y \texttt{healthy} siguen siendo las que mejor se detectan.
\item Las clases \texttt{Target\_Spot}, \texttt{powdery\_mildew}, \texttt{Early\_blight} y \texttt{Septoria\_leaf\_spot} siguen siendo las más conflictivas.
\end{bulletlist}

Se puede decir que este modelo rinde igual en términos generales, pero pierde sensibilidad en las clases menos frecuentes. Esto demuestra la función de los pesos en las clases, es decir el balanceo de las mismas.

El modelo con obtenido en la subsección \ref{sec:sec5.1.1} equilibra mejor los resultados sin sacrificar precisión general, por lo que es la opción más sólida para un sistema de diagnóstico de enfermedades, donde todas las clases tienen importancia clínica. Por tanto  el modelo que se seguirá mejorando en la suubsección subsección \ref{sec:sec5.1.3} 


\subsection{Entrenamiento 3}\label{sec:sec5.1.3}



\section{Modelo \textit{EfficientNetB0}}\label{sec:sec5.2}

En esta sección se van a mostrar los resultados del entrenamiento del modelo descrito en la subsección \ref{sec:sec4.4.2}. Este entrenamiento se ha realizado usando los pesos de clases descritos en el Cuadro \ref{tab:pesos_por_clase_entrenamiento}. Solo se ha sometido a 10 épocas y se han usado los callbacks de \textit{ModelCheckpoint} e \textit{HistorySaver}, ya que el objetivo de este entrenamiento es observar la tendencia inicial.

Para mostrar los resultados de este entrenamiento se va a comenzar mostrando las métricas recogidas en el fichero generado por el callback \textit{HistorySaver} en la Figura \ref{fig:fig14}.

\begin{figure}[ht]
\begin{center}
\includegraphics[scale=0.5]{./Images/historico_metricas_efficientnetb0_1.png}
\caption{\headlinecolor{\underline{Histórico de métricas del entrenamiento 2 del modelo \textit{EfficientNetB0}}}}
\label{fig:fig14}
\end{center}
\end{figure}

En esta figura se puede observar el comportamiento de las métricas de precisión y pérdida de entrenamiento y validación a lo largo de las épocas a las que se ha sometido el modelo descrito en la subsección \ref{sec:sec4.4.1} en el entrenamiento. A continuación se describe lo que se puede interpretar:  

\begin{bulletlist}
\item Precisión de entrenamiento: Queda constante en aproximadamente 0.09, un valor muy lejano a 1, lo que demuestra que el modelo no aprende de los datos de entrenamiento.
\item Pérdida de entrenamiento: Queda practicamente constante en un valor cercano a 2.4, bastante lejano a 0.
\item Precisión de validación: Oscila entre valores cercanos a 0.1, por lo que el modelo tampoco generaliza.
\item Pérdida de validación: Oscila entre valores cercanos a 2.4, bastante lejano a 0.
\end{bulletlist}

El modelo no está aprendiendo absolutamente nada más allá del azar. Para mejorar esta situación se descongelarán algunas capas superiores del modelo base \textit{EfficientNetB0}, haciendo uso de la técnica de \textit{fine tuning}.


\section{Modelo \textit{NASNetMobile}}\label{sec:sec5.3}

En esta sección se van a mostrar los resultados del entrenamiento del modelo descrito en la subsección \ref{sec:sec4.4.3}. A este modelo se han aplicado varios entrenamientos distintos explicados en las subsecciones \ref{sec:sec5.3.1}, .


\subsection{Entrenamiento 1}\label{sec:sec5.3.1}

Para mostrar los resultados de este entrenamiento se va a comenzar mostrando las métricas recogidas en el fichero generado por el callback \textit{HistorySaver} en la Figura \ref{fig:fig15}.

\begin{figure}[ht]
\begin{center}
\includegraphics[scale=0.5]{./Images/historico_metricas_nasnetmobile_1.png}
\caption{\headlinecolor{\underline{Histórico de métricas del entrenamiento 1 del modelo \textit{NASNetMobile}}}}
\label{fig:fig15}
\end{center}
\end{figure}

En esta figura se puede observar el comportamiento de las métricas de precisión y pérdida de entrenamiento y validación a lo largo de las épocas a las que se ha sometido el modelo descrito en la subsección \ref{sec:sec4.4.1} en el entrenamiento. A continuación se describe lo que se puede interpretar:  

\begin{bulletlist}
\item Precisión de entrenamiento: Comienza alrededor de 0.5 y sube rápidamente a un valor cercano a 0.7, mostrando que el modelo aprende bien de los datos de entrenamiento.
\item Pérdida de entrenamiento: Disminuye de un valor cercano a 1.3 hasta cerca de 0.7, lo que confirma que el modelo está optimizando correctamente con la función de pérdida elegida para los datos de entrenamiento.
\item Precisión de validación: Aumenta de un valor cercano a 0.65 a un valor cercano a 0.75, lo que muestra que el modelo aprende bien de datos distintos a los de entrenamiento.
\item Pérdida de validación: Disminuye de un valor cercano a 1.1 a un valor cercano a 0.8, confirmando que la función de pérdida optimiza bien el modelo.
\end{bulletlist}

El modelo mejora rápidamente durante las primeras 5 épocas. A partir de ese punto, tanto la precisión de entrenmaiento como la de validación se estabilizan alrededor del 75\%, lo cual indica que el modelo ha aprendido bien las características generales, pero está alcanzando su límite. 

Para mejorar este resultado se podría entrenar más épocas añadiendo los callbacks \textit{EarlyStopping} para que pare la ejecución si el modelo no mejora y con \textit{ReduceLROnPlateau} para que disminuya el \textit{learning rate} en el entrenamiento y haga que no se estanquen sus valores.


\chapter{Conclusiones}\label{cap:cap6}

Se selecciona el mejor modelo y se muestra una gráfica probando el modelo (desarrollar)


\appendix
\chapter{Anexo I: Ejemplo de anexo}\label{cap:anexo1}
Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.

\begin{enumerate}[label=\bfseries\headlinecolor\arabic*.]
\item Primer elemento.
\item Segundo elemento
\item Tercer elemento.
\begin{enumerate}[label=\alph*)]
\item Primer subelemento.
\item Segundo subelemento.
\begin{itemize}[label=$\bullet$]
\item Primer punto.
\item Segundo punto.
\end{itemize}

\end{enumerate}

\end{enumerate}


\printbibliography

\end{document}
